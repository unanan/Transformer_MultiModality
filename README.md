# Transformer_MultiModality
A project wrapping the codes for multi-modalities of Transformer, aiming to reuse it simply.

- Please explore the project by yourself for more details.

### Brief
Integrated some open codes of Transformer(Google version), AdamW, SGDW, and etc. to this repo for training multi-modalities task.
Specifically, transformer for multi-modalities task can be used on training variable length of sequences and variable shape of images.

### Reference
Referenced the blog: http://nlp.seas.harvard.edu/2018/04/03/attention.html

### TODOs
- Not finished yet
